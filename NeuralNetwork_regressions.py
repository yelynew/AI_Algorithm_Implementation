# -*- coding: utf-8 -*-
"""AS2.jpynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pFWIYwz-RJZVMvJM32kGE0FZsizLk9_F

Loading dataset
"""

!pip install seaborn

!pip install git+https://github.com/tensorflow/docs

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from matplotlib import pyplot
import numpy as np
import pandas as pd
import seaborn as sns
import io
# Load data set
url = 'http://www.cs.ndsu.nodak.edu/~siludwig/regressiondataset.csv'
raw_dataset = pd.read_csv(url,
 na_values='?', comment='\t',
 sep=',', skipinitialspace=True)
dataset = raw_dataset.copy()
print(dataset)

"""Split data to train set and test set


"""

import tensorflow_docs as tfdocs
import tensorflow_docs.plots
import tensorflow_docs.modeling

dataset = dataset.dropna()
print(dataset)
train_dataset = dataset.sample(frac=0.85, random_state=0)
test_dataset = dataset.drop(train_dataset.index)
train_data_X = train_dataset.copy()
test_data_X = test_dataset.copy()
train_X = train_data_X.iloc[:,:-1]
test_X = test_data_X.iloc[:,:-1]
train_Y = train_data_X.iloc[:,-1:]
test_Y = test_data_X.iloc[:,-1:]
#print(train_Y)

train_stats = train_dataset.describe()
#train_stats.pop("y")
train_stats = train_stats.transpose()
train_stats

def norm(x):
  return (x - train_stats['mean']) / train_stats['std']
normed_train_data = norm(train_dataset)
normed_test_data = norm(test_dataset)

# import tensorflow as tf

# inputs = tf.keras.Input(shape=(3,))
# x = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)
# outputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)
# model = tf.keras.Model(inputs=inputs, outputs=outputs)

"""tf.Keras.Model"""

'''!pip install tensorflow-gpu==1.14.0
import tensorflow as tf
import numpy as np

import tensorflow as tf
from tensorflow import keras as tfk
import pandas as pd

print(tf.__version__)


def build_model(n_features, **kwargs):
    model = tfk.models.Sequential([
        tfk.layers.Dense(1, input_shape=[n_features, ], **kwargs)
    ])
    optimizer = tfk.optimizers.SGD()
    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=[tfk.metrics.binary_accuracy])
    return model


class PrintDot(tfk.callbacks.Callback):
    def on_epoch_end(self, epoch, logs):
        if epoch % 100 == 0:
            print('')
        print('.', end='')


EPOCHS = 1000
BATCH_SIZE = None
d = train_X.shape[1]

linear = build_model(d)
sigmoid = build_model(d, activation=tfk.activations.sigmoid)

print(train_X.shape)
print(train_Y.shape)
print(linear.summary())
print(sigmoid.summary())

linear_res = linear.fit(
    train_X, train_Y, batch_size=BATCH_SIZE,
    epochs=EPOCHS, validation_split=0.2, verbose=0,
    callbacks=[PrintDot()])
sigmoid_res = sigmoid.fit(
    train_X, train_Y, batch_size=BATCH_SIZE,
    epochs=EPOCHS, validation_split=0.2, verbose=0,
    callbacks=[PrintDot()])'''

import tensorflow as tf

class MyModel(tf.keras.Model):

  def __init__(self):
    super(MyModel, self).__init__()
    self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)
    self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.relu)
    self.dropout = tf.keras.layers.Dropout(0.5)

  def call(self, inputs, training=False):
    x = self.dense1(inputs)
    if training:
      x = self.dropout(x, training=training)
    return self.dense2(x)

model1 = MyModel()
model1.compile(optimizer="Adam", loss="mse", metrics=["mae","mse"])
model1.fit(train_X, train_Y)
model1.summary()
model2 = MyModel()
model2.compile(optimizer="RMSprop", loss="mse", metrics=["mae","mse"])
model2.fit(train_X, train_Y)
model2.summary()
model3 = MyModel()
model3.compile(optimizer="Adam", loss="mae", metrics=["mae","mse"])
model3.fit(train_X, train_Y)
model3.summary()
model4 = MyModel()
model4.compile(optimizer="RMSprop", loss="mae", metrics=["mae","mse"])
model4.fit(train_X, train_Y)
model4.summary()

class MyModel2(tf.keras.Model):

  def __init__(self):
    super(MyModel2, self).__init__()
    self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.softmax)
    self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)
    self.dropout = tf.keras.layers.Dropout(0.5)

  def call(self, inputs, training=False):
    x = self.dense1(inputs)
    if training:
      x = self.dropout(x, training=training)
    return self.dense2(x)


model5 = MyModel2()
model5.compile(optimizer="Adam", loss="mse", metrics=["mae","mse"])
model5.fit(train_X, train_Y)
model5.summary()
model6 = MyModel2()
model6.compile(optimizer="RMSprop", loss="mse", metrics=["mae","mse"])
model6.fit(train_X, train_Y)
model6.summary()
model7 = MyModel2()
model7.compile(optimizer="Adam", loss="mae", metrics=["mae","mse"])
model7.fit(train_X, train_Y)
model7.summary()
model8 = MyModel2()
model8.compile(optimizer="RMSprop", loss="mae", metrics=["mae","mse"])
model8.fit(train_X, train_Y)
model8.summary()

example_batch = train_X[:10]
print(type(example_batch))
example_result = model1.predict(example_batch)
example_result

class PrintDot(keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs):
    if epoch % 100 == 0: print('')
    print('.', end='')

EPOCHS = 1000

history1 = model1.fit(
  #train_X,train_Y,
  #normed_train_data, train_dataset,
  train_X,train_Y,
  epochs=EPOCHS, validation_split = 0.2, verbose=0, callbacks=[tfdocs.modeling.EpochDots()])

history2 = model2.fit(train_X,train_Y, epochs=EPOCHS, validation_split = 0.2, verbose=0, callbacks=[tfdocs.modeling.EpochDots()])
history3 = model3.fit(train_X,train_Y, epochs=EPOCHS, validation_split = 0.2, verbose=0, callbacks=[tfdocs.modeling.EpochDots()])
history4 = model4.fit(train_X,train_Y, epochs=EPOCHS, validation_split = 0.2, verbose=0, callbacks=[tfdocs.modeling.EpochDots()])
history5 = model5.fit(train_X,train_Y, epochs=EPOCHS, validation_split = 0.2, verbose=0, callbacks=[tfdocs.modeling.EpochDots()])
history6 = model6.fit(train_X,train_Y, epochs=EPOCHS, validation_split = 0.2, verbose=0, callbacks=[tfdocs.modeling.EpochDots()])
history7 = model7.fit(train_X,train_Y, epochs=EPOCHS, validation_split = 0.2, verbose=0, callbacks=[tfdocs.modeling.EpochDots()])
history8 = model8.fit(train_X,train_Y, epochs=EPOCHS, validation_split = 0.2, verbose=0, callbacks=[tfdocs.modeling.EpochDots()])

hist = pd.DataFrame(history1.history)
hist['epoch'] = history1.epoch
hist.tail()

import matplotlib.pyplot as plt

def plot_history(history):
  hist = pd.DataFrame(history.history)
  hist['epoch'] = history.epoch
  print(hist['mse'])

  plt.figure(figsize=(8,12))

  plt.subplot(2,1,1)
  plt.xlabel('Epoch')
  plt.ylabel('Mean Abs Error [MPG]')
  plt.plot(hist['epoch'], hist['mae'],
           label='MAE Train Error')
  plt.plot(hist['epoch'], hist['val_mae'], label = 'Val Error')
  plt.legend()
  #plt.show()

  plt.subplot(2,1,2)
  plt.xlabel('Epoch')
  plt.ylabel('Mean Square Error [$MPG^2$]')
  plt.plot(hist['epoch'], hist['mse'],
           label='Train Error')
  plt.plot(hist['epoch'], hist['val_mse'],
           label = 'Val Error')
  plt.legend()
  plt.show()

plot_history(history1)

plot_history(history2)
plot_history(history3)
plot_history(history4)
plot_history(history5)
plot_history(history6)
plot_history(history7)
plot_history(history8)

plt.plot(history.history['mse'], label='MAE (training data)')
plt.plot(history.history['val_mse'], label='MAE (validation data)')
#model = MyModel()
#model.compile(optimizer="Adam", loss="mse", metrics=["mae","mse"])

# patience 매개변수는 성능 향상을 체크할 에포크 횟수입니다
# The patience parameter is the amount of epochs to check for improvement
early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)

early_history1 = model1.fit(train_X, train_Y, epochs=EPOCHS,
                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])

plot_history(early_history1)
plt.show()

early_history2 = model2.fit(train_X, train_Y, epochs=EPOCHS,
                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])

plot_history(early_history2)
plt.show()

early_history3 = model3.fit(train_X, train_Y, epochs=EPOCHS,
                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])

plot_history(early_history3)
plt.show()

early_history4 = model4.fit(train_X, train_Y, epochs=EPOCHS,
                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])

plot_history(early_history4)
plt.show()

early_history5 = model5.fit(train_X, train_Y, epochs=EPOCHS,
                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])

plot_history(early_history5)
plt.show()

early_history6 = model6.fit(train_X, train_Y, epochs=EPOCHS,
                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])

plot_history(early_history6)
plt.show()

early_history7 = model7.fit(train_X, train_Y, epochs=EPOCHS,
                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])

plot_history(early_history7)
plt.show()

early_history8 = model8.fit(train_X, train_Y, epochs=EPOCHS,
                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])

plot_history(early_history8)
plt.show()

'''model = MyModel()
model.compile(optimizer="Adam", loss="mse", metrics=["mae","mse"])

# The patience parameter is the amount of epochs to check for improvement
early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)

early_history = model.fit(train_X, train_Y, 
                    epochs=EPOCHS, validation_split = 0.25, verbose=0, 
                    callbacks=[early_stop, tfdocs.modeling.EpochDots()])

#print(train_Y)'''

plotter = tfdocs.plots.HistoryPlotter(smoothing_std=2)
plotter.plot({'Early Stopping': early_history1}, metric = "mse")
#plt.ylim([0, 500])
plt.ylabel('MSE')

loss, mae, mse = model1.evaluate(test_X, test_Y, verbose=2)

print("Testing set Mean Squared Error: {:5.2f}".format(mse))
loss, mae, mse = model2.evaluate(test_X, test_Y, verbose=2)

print("Testing set Mean Squared Error: {:5.2f}".format(mse))
loss, mae, mse = model3.evaluate(test_X, test_Y, verbose=2)

print("Testing set Mean Squared Error: {:5.2f}".format(mse))
loss, mae, mse = model4.evaluate(test_X, test_Y, verbose=2)

print("Testing set Mean Squared Error: {:5.2f}".format(mse))
loss, mae, mse = model5.evaluate(test_X, test_Y, verbose=2)

print("Testing set Mean Squared Error: {:5.2f}".format(mse))
loss, mae, mse = model6.evaluate(test_X, test_Y, verbose=2)

print("Testing set Mean Squared Error: {:5.2f}".format(mse))
loss, mae, mse = model7.evaluate(test_X, test_Y, verbose=2)

print("Testing set Mean Squared Error: {:5.2f}".format(mse))
loss, mae, mse = model8.evaluate(test_X, test_Y, verbose=2)

print("Testing set Mean Squared Error: {:5.2f}".format(mse))

test_predictions1 = model1.predict(test_X).flatten()

plt.scatter(test_Y, test_predictions1)
plt.xlabel('True Values [MPG]')
plt.ylabel('Predictions [MPG]')
plt.axis('equal')
plt.axis('square')
plt.xlim([0,plt.xlim()[1]])
plt.ylim([0,plt.ylim()[1]])
_ = plt.plot([-100, 100], [-100, 100])

test_predictions2 = model2.predict(test_X).flatten()

plt.scatter(test_Y, test_predictions2)
plt.xlabel('True Values [MPG]')
plt.ylabel('Predictions [MPG]')
plt.axis('equal')
plt.axis('square')
plt.xlim([0,plt.xlim()[1]])
plt.ylim([0,plt.ylim()[1]])
_ = plt.plot([-100, 100], [-100, 100])


test_predictions3 = model3.predict(test_X).flatten()

plt.scatter(test_Y, test_predictions3)
plt.xlabel('True Values [MPG]')
plt.ylabel('Predictions [MPG]')
plt.axis('equal')
plt.axis('square')
plt.xlim([0,plt.xlim()[1]])
plt.ylim([0,plt.ylim()[1]])
_ = plt.plot([-100, 100], [-100, 100])

test_predictions4 = model4.predict(test_X).flatten()

plt.scatter(test_Y, test_predictions4)
plt.xlabel('True Values [MPG]')
plt.ylabel('Predictions [MPG]')
plt.axis('equal')
plt.axis('square')
plt.xlim([0,plt.xlim()[1]])
plt.ylim([0,plt.ylim()[1]])
_ = plt.plot([-100, 100], [-100, 100])


test_predictions5 = model5.predict(test_X).flatten()

plt.scatter(test_Y, test_predictions5)
plt.xlabel('True Values [MPG]')
plt.ylabel('Predictions [MPG]')
plt.axis('equal')
plt.axis('square')
plt.xlim([0,plt.xlim()[1]])
plt.ylim([0,plt.ylim()[1]])
_ = plt.plot([-100, 100], [-100, 100])


test_predictions6 = model6.predict(test_X).flatten()

plt.scatter(test_Y, test_predictions6)
plt.xlabel('True Values [MPG]')
plt.ylabel('Predictions [MPG]')
plt.axis('equal')
plt.axis('square')
plt.xlim([0,plt.xlim()[1]])
plt.ylim([0,plt.ylim()[1]])
_ = plt.plot([-100, 100], [-100, 100])


test_predictions7 = model7.predict(test_X).flatten()

plt.scatter(test_Y, test_predictions7)
plt.xlabel('True Values [MPG]')
plt.ylabel('Predictions [MPG]')
plt.axis('equal')
plt.axis('square')
plt.xlim([0,plt.xlim()[1]])
plt.ylim([0,plt.ylim()[1]])
_ = plt.plot([-100, 100], [-100, 100])


test_predictions8 = model8.predict(test_X).flatten()

plt.scatter(test_Y, test_predictions8)
plt.xlabel('True Values [MPG]')
plt.ylabel('Predictions [MPG]')
plt.axis('equal')
plt.axis('square')
plt.xlim([0,plt.xlim()[1]])
plt.ylim([0,plt.ylim()[1]])
_ = plt.plot([-100, 100], [-100, 100])

predictions=test_predictions1.reshape(1500,1)
error = predictions - test_Y
plt.hist(error, bins = 25)
plt.xlabel("Prediction Error")
_ = plt.ylabel("Count")

predictions=test_predictions2.reshape(1500,1)
error = predictions - test_Y
plt.hist(error, bins = 25)
plt.xlabel("Prediction Error")
_ = plt.ylabel("Count")

predictions=test_predictions3.reshape(1500,1)
error = predictions - test_Y
plt.hist(error, bins = 25)
plt.xlabel("Prediction Error")
_ = plt.ylabel("Count")

predictions=test_predictions4.reshape(1500,1)
error = predictions - test_Y
plt.hist(error, bins = 25)
plt.xlabel("Prediction Error")
_ = plt.ylabel("Count")

predictions=test_predictions5.reshape(1500,1)
error = predictions - test_Y
plt.hist(error, bins = 25)
plt.xlabel("Prediction Error")
_ = plt.ylabel("Count")

predictions=test_predictions6.reshape(1500,1)
error = predictions - test_Y
plt.hist(error, bins = 25)
plt.xlabel("Prediction Error")
_ = plt.ylabel("Count")

predictions=test_predictions7.reshape(1500,1)
error = predictions - test_Y
plt.hist(error, bins = 25)
plt.xlabel("Prediction Error")
_ = plt.ylabel("Count")

predictions=test_predictions8.reshape(1500,1)
error = predictions - test_Y
plt.hist(error, bins = 25)
plt.xlabel("Prediction Error")
_ = plt.ylabel("Count")

"""tf.Keras.Sequential model"""

def build_model():
  model = keras.Sequential([
    layers.Dense(64, activation='relu', input_shape=[len(train_dataset.keys())]),
    layers.Dense(64, activation='relu'),
    layers.Dense(1)
  ])

  optimizer = tf.keras.optimizers.Adam(0.001)

  model.compile(loss='mse',
                optimizer=optimizer,
                metrics=['mae', 'mse'])
  return model

def build_model2():
  model = keras.Sequential([
    layers.Dense(64, activation='relu', input_shape=[len(train_dataset.keys())]),
    layers.Dense(64, activation='relu'),
    layers.Dense(1)
  ])

  optimizer = tf.keras.optimizers.RMSprop(0.001)

  model.compile(loss='mse',
                optimizer=optimizer,
                metrics=['mae', 'mse'])
  return model

def build_model3():
  model = keras.Sequential([
    layers.Dense(64, activation='relu', input_shape=[len(train_dataset.keys())]),
    layers.Dense(64, activation='relu'),
    layers.Dense(1)
  ])

  optimizer = tf.keras.optimizers.Adam(0.001)

  model.compile(loss='mae',
                optimizer=optimizer,
                metrics=['mae', 'mse'])
  return model

def build_model4():
  model = keras.Sequential([
    layers.Dense(64, activation='relu', input_shape=[len(train_dataset.keys())]),
    layers.Dense(64, activation='relu'),
    layers.Dense(1)
  ])

  optimizer = tf.keras.optimizers.RMSprop(0.001)

  model.compile(loss='mae',
                optimizer=optimizer,
                metrics=['mae', 'mse'])
  return model

model9 = build_model()
model9.summary()
model10 = build_model2()
model10.summary()
model11 = build_model3()
model11.summary()
model12 = build_model4()
model12.summary()

def build_model5():
  model = keras.Sequential([
    layers.Dense(64, activation='softmax', input_shape=[len(train_dataset.keys())]),
    layers.Dense(64, activation='softmax'),
    layers.Dense(1)
  ])

  optimizer = tf.keras.optimizers.Adam(0.001)

  model.compile(loss='mse',
                optimizer=optimizer,
                metrics=['mae', 'mse'])
  return model

def build_model6():
  model = keras.Sequential([
    layers.Dense(64, activation='softmax', input_shape=[len(train_dataset.keys())]),
    layers.Dense(64, activation='softmax'),
    layers.Dense(1)
  ])

  optimizer = tf.keras.optimizers.RMSprop(0.001)

  model.compile(loss='mse',
                optimizer=optimizer,
                metrics=['mae', 'mse'])
  return model

def build_model7():
  model = keras.Sequential([
    layers.Dense(64, activation='softmax', input_shape=[len(train_dataset.keys())]),
    layers.Dense(64, activation='softmax'),
    layers.Dense(1)
  ])

  optimizer = tf.keras.optimizers.Adam(0.001)

  model.compile(loss='mae',
                optimizer=optimizer,
                metrics=['mae', 'mse'])
  return model

def build_model8():
  model = keras.Sequential([
    layers.Dense(64, activation='softmax', input_shape=[len(train_dataset.keys())]),
    layers.Dense(64, activation='softmax'),
    layers.Dense(1)
  ])

  optimizer = tf.keras.optimizers.RMSprop(0.001)

  model.compile(loss='mae',
                optimizer=optimizer,
                metrics=['mae', 'mse'])
  return model

model13 = build_model5()
model13.summary()
model14 = build_model6()
model14.summary()
model15 = build_model7()
model15.summary()
model16 = build_model8()
model16.summary()

# example_batch = train_Y[:10]
example_batch = normed_train_data[:10]
#print(example_batch)
example_result9 = model9.predict(example_batch)
example_result9
example_result10 = model10.predict(example_batch)
example_result10
example_result11 = model11.predict(example_batch)
example_result11
example_result12 = model12.predict(example_batch)
example_result12
example_result13 = model13.predict(example_batch)
example_result13
example_result14 = model14.predict(example_batch)
example_result14
example_result15 = model15.predict(example_batch)
example_result15
example_result16 = model16.predict(example_batch)
#print(example_result16)

"""sequential model fit"""

class PrintDot(keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs):
    if epoch % 100 == 0: print('')
    print('.', end='')

EPOCHS = 1000

history9 = model9.fit(
  #train_X,train_Y,
  #normed_train_data, train_dataset,
  normed_train_data,train_Y,
  epochs=EPOCHS, validation_split = 0.2, verbose=0, callbacks=[tfdocs.modeling.EpochDots()])
  #epochs=EPOCHS, validation_split = 0.2, verbose=0, callbacks=[PrintDot()])

print(history9)

history10 = model10.fit(  normed_train_data,train_Y, epochs=EPOCHS, validation_split = 0.2, verbose=0, callbacks=[tfdocs.modeling.EpochDots()])

history11 = model11.fit(  normed_train_data,train_Y, epochs=EPOCHS, validation_split = 0.2, verbose=0, callbacks=[tfdocs.modeling.EpochDots()])

history12 = model12.fit(  normed_train_data,train_Y, epochs=EPOCHS, validation_split = 0.2, verbose=0, callbacks=[tfdocs.modeling.EpochDots()])

history13 = model13.fit(  normed_train_data,train_Y, epochs=EPOCHS, validation_split = 0.2, verbose=0, callbacks=[tfdocs.modeling.EpochDots()])

history14 = model14.fit(  normed_train_data,train_Y, epochs=EPOCHS, validation_split = 0.2, verbose=0, callbacks=[tfdocs.modeling.EpochDots()])

history15 = model15.fit(  normed_train_data,train_Y, epochs=EPOCHS, validation_split = 0.2, verbose=0, callbacks=[tfdocs.modeling.EpochDots()])

history16 = model16.fit(  normed_train_data,train_Y, epochs=EPOCHS, validation_split = 0.2, verbose=0, callbacks=[tfdocs.modeling.EpochDots()])

hist = pd.DataFrame(history9.history)
hist['epoch'] = history9.epoch
hist.tail()

# import matplotlib.pyplot as plt

# def plot_history(history):
#   hist = pd.DataFrame(history.history)
#   hist['epoch'] = history.epoch

#   plt.figure(figsize=(8,12))


#   plt.subplot(2,1,1)
#   plt.xlabel('Epoch')
#   plt.ylabel('Mean Square Error [$MPG^2$]')
#   plt.plot(hist['epoch'], hist['loss'],
#            label='Train Error')
#   plt.plot(hist['epoch'], hist['val_loss'],
#            label = 'Val Error')
  
#   plt.subplot(2,1,2)
#   plt.xlabel('Epoch')
#   plt.ylabel('MAE [$MPG^2$]')
#   plt.plot(hist['epoch'], hist['mae'],
#            label='Train Error')
#   plt.plot(hist['epoch'], hist['val_mae'],
#            label = 'Val Error')
  


#   plt.ylim([0,20])
#   plt.legend()
#   plt.show()

# plot_history(history)
import matplotlib.pyplot as plt

def plot_history(history):
  hist = pd.DataFrame(history.history)
  hist['epoch'] = history.epoch
  print(hist['mse'])

  plt.figure(figsize=(8,12))

  plt.subplot(2,1,1)
  plt.xlabel('Epoch')
  plt.ylabel('Mean Abs Error [MPG]')
  plt.plot(hist['epoch'], hist['mae'],
           label='MAE Train Error')
  plt.plot(hist['epoch'], hist['val_mae'], label = 'Val Error')
  plt.legend()
  #plt.show()

  plt.subplot(2,1,2)
  plt.xlabel('Epoch')
  plt.ylabel('Mean Square Error [$MPG^2$]')
  plt.plot(hist['epoch'], hist['mse'],
           label='Train Error')
  plt.plot(hist['epoch'], hist['val_mse'],
           label = 'Val Error')
  plt.legend()
  plt.show()

plot_history(history9)

plot_history(history10)

plot_history(history11)

plot_history(history12)

plot_history(history13)

plot_history(history14)

plot_history(history15)

plot_history(history16)

#plotter = tfdocs.plots.HistoryPlotter(smoothing_std=2)

#plt=plotter.plot({'Basic': history}, metric = "mse")
#plt.plot(history.history['loss'], label='MAE (training data)')
#plt.plot(history.history['val_loss'], label='MAE (validation data)')
#plt.plot(hist['epoch'], hist['mae'],
#           label='Train Error')
#plt.show()
#plt.ylim([0, 450])
#plt.ylabel('MSE')

plt.plot(history.history['mse'], label='MAE (training data)')
plt.plot(history.history['val_mse'], label='MAE (validation data)')
#model2 = build_model()

# patience 매개변수는 성능 향상을 체크할 에포크 횟수입니다
# The patience parameter is the amount of epochs to check for improvement
early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)

early_history9 = model9.fit(normed_train_data, train_dataset, epochs=EPOCHS,
                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])

plot_history(early_history9)
plt.show()

early_history10 = model10.fit(normed_train_data, train_dataset, epochs=EPOCHS,
                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])

plot_history(early_history10)
plt.show()

early_history11 = model11.fit(normed_train_data, train_dataset, epochs=EPOCHS,
                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])

plot_history(early_history11)
plt.show()

early_history12 = model12.fit(normed_train_data, train_dataset, epochs=EPOCHS,
                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])

plot_history(early_history12)
plt.show()

early_history13 = model13.fit(normed_train_data, train_dataset, epochs=EPOCHS,
                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])

plot_history(early_history13)
plt.show()

early_history14 = model14.fit(normed_train_data, train_dataset, epochs=EPOCHS,
                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])

plot_history(early_history14)
plt.show()

early_history15 = model15.fit(normed_train_data, train_dataset, epochs=EPOCHS,
                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])

plot_history(early_history15)
plt.show()

early_history16 = model16.fit(normed_train_data, train_dataset, epochs=EPOCHS,
                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])

plot_history(early_history16)
plt.show()

'''model2 = build_model()

# The patience parameter is the amount of epochs to check for improvement
early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)

early_history = model2.fit(normed_train_data, train_Y, 
                    epochs=EPOCHS, validation_split = 0.25, verbose=0, 
                    callbacks=[early_stop, tfdocs.modeling.EpochDots()])

print(train_dataset)'''

plotter.plot({'Early Stopping': early_history9}, metric = "mse")
#plt.ylim([0, 500])
plt.ylabel('MSE')

loss, mae, mse = model9.evaluate(normed_test_data, test_Y, verbose=2)

print("Testing set Mean Squared Error: {:5.2f}".format(mse))

loss, mae, mse = model10.evaluate(normed_test_data, test_Y, verbose=2)

print("Testing set Mean Squared Error: {:5.2f}".format(mse))

loss, mae, mse = model11.evaluate(normed_test_data, test_Y, verbose=2)

print("Testing set Mean Squared Error: {:5.2f}".format(mse))
loss, mae, mse = model12.evaluate(normed_test_data, test_Y, verbose=2)

print("Testing set Mean Squared Error: {:5.2f}".format(mse))

loss, mae, mse = model13.evaluate(normed_test_data, test_Y, verbose=2)

print("Testing set Mean Squared Error: {:5.2f}".format(mse))
loss, mae, mse = model14.evaluate(normed_test_data, test_Y, verbose=2)

print("Testing set Mean Squared Error: {:5.2f}".format(mse))
loss, mae, mse = model15.evaluate(normed_test_data, test_Y, verbose=2)

print("Testing set Mean Squared Error: {:5.2f}".format(mse))
loss, mae, mse = model16.evaluate(normed_test_data, test_Y, verbose=2)

print("Testing set Mean Squared Error: {:5.2f}".format(mse))

test_predictions9 = model9.predict(normed_test_data).flatten()

a = plt.axes(aspect='equal')
plt.scatter(test_Y, test_predictions9)
plt.xlabel('True Values')
plt.ylabel('Predictions')
#plt.show()
lims = [0, 900]
plt.xlim([0,150])
plt.ylim(lims)
_ = plt.plot([0,150], lims)

test_predictions10 = model10.predict(normed_test_data).flatten()

a = plt.axes(aspect='equal')
plt.scatter(test_Y, test_predictions10)
plt.xlabel('True Values')
plt.ylabel('Predictions')
#plt.show()
lims = [0, 900]
plt.xlim([0,150])
plt.ylim(lims)
_ = plt.plot([0,150], lims)

test_predictions11 = model11.predict(normed_test_data).flatten()

a = plt.axes(aspect='equal')
plt.scatter(test_Y, test_predictions11)
plt.xlabel('True Values')
plt.ylabel('Predictions')
#plt.show()
lims = [0, 900]
plt.xlim([0,150])
plt.ylim(lims)
_ = plt.plot([0,150], lims)

test_predictions12 = model12.predict(normed_test_data).flatten()

a = plt.axes(aspect='equal')
plt.scatter(test_Y, test_predictions12)
plt.xlabel('True Values')
plt.ylabel('Predictions')
#plt.show()
lims = [0, 900]
plt.xlim([0,150])
plt.ylim(lims)
_ = plt.plot([0,150], lims)

test_predictions13 = model13.predict(normed_test_data).flatten()

a = plt.axes(aspect='equal')
plt.scatter(test_Y, test_predictions13)
plt.xlabel('True Values')
plt.ylabel('Predictions')
#plt.show()
lims = [0, 900]
plt.xlim([0,150])
plt.ylim(lims)
_ = plt.plot([0,150], lims)

test_predictions14 = model14.predict(normed_test_data).flatten()

a = plt.axes(aspect='equal')
plt.scatter(test_Y, test_predictions14)
plt.xlabel('True Values')
plt.ylabel('Predictions')
#plt.show()
lims = [0, 900]
plt.xlim([0,150])
plt.ylim(lims)
_ = plt.plot([0,150], lims)

test_predictions15 = model15.predict(normed_test_data).flatten()

a = plt.axes(aspect='equal')
plt.scatter(test_Y, test_predictions15)
plt.xlabel('True Values')
plt.ylabel('Predictions')
#plt.show()
lims = [0, 900]
plt.xlim([0,150])
plt.ylim(lims)
_ = plt.plot([0,150], lims)

test_predictions16 = model16.predict(normed_test_data).flatten()

a = plt.axes(aspect='equal')
plt.scatter(test_Y, test_predictions16)
plt.xlabel('True Values')
plt.ylabel('Predictions')
#plt.show()
lims = [0, 900]
plt.xlim([0,150])
plt.ylim(lims)
_ = plt.plot([0,150], lims)

predictions9=test_predictions9.reshape(1500,1)
error = predictions9 - test_Y
plt.hist(error, bins = 25)
plt.xlabel("Prediction Error")
_ = plt.ylabel("Count")

predictions10=test_predictions10.reshape(1500,1)
error = predictions10 - test_Y
plt.hist(error, bins = 25)
plt.xlabel("Prediction Error")
_ = plt.ylabel("Count")

predictions11=test_predictions11.reshape(1500,1)
error = predictions11 - test_Y
plt.hist(error, bins = 25)
plt.xlabel("Prediction Error")
_ = plt.ylabel("Count")

predictions12=test_predictions12.reshape(1500,1)
error = predictions12 - test_Y
plt.hist(error, bins = 25)
plt.xlabel("Prediction Error")
_ = plt.ylabel("Count")

predictions13=test_predictions13.reshape(1500,1)
error = predictions13 - test_Y
plt.hist(error, bins = 25)
plt.xlabel("Prediction Error")
_ = plt.ylabel("Count")

predictions14=test_predictions14.reshape(1500,1)
error = predictions14 - test_Y
plt.hist(error, bins = 25)
plt.xlabel("Prediction Error")
_ = plt.ylabel("Count")

predictions15=test_predictions15.reshape(1500,1)
error = predictions15 - test_Y
plt.hist(error, bins = 25)
plt.xlabel("Prediction Error")
_ = plt.ylabel("Count")

predictions16=test_predictions16.reshape(1500,1)
error = predictions16 - test_Y
plt.hist(error, bins = 25)
plt.xlabel("Prediction Error")
_ = plt.ylabel("Count")

# model = build_model()

# # patience 매개변수는 성능 향상을 체크할 에포크 횟수입니다
# early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)

# history = model.fit(train_X, train_Y, epochs=EPOCHS,
#                     #validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])
#                     validation_split = 0.2, verbose=0, callbacks=[early_stop, tfdocs.modeling.EpochDots()])
# plot_history(history)